{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "555f3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.measure import label\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imread, imwrite\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18661358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(im):\n",
    "    threshold = 200 # threshold for green channel\n",
    "\n",
    "    mask = (im[:,:,1] > threshold).astype(float)\n",
    "    blurred = gaussian_filter(mask, sigma=2)\n",
    "    mask = blurred < 0.70\n",
    "\n",
    "    cc_threshold = 100000 # connected components threshold size (keep above)\n",
    "    mask = remove_small_objects(mask, min_size=cc_threshold)\n",
    "\n",
    "    labeled_mask = label(mask, connectivity=2)\n",
    "    return labeled_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6837ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pth = 'test_data/cropped_sections'\n",
    "images = sorted([os.path.join(im_pth, f) for f in os.listdir(im_pth) if f.endswith('.tif')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6bbcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_mask(mask: np.ndarray, ds: int) -> np.ndarray:\n",
    "    \"\"\"Down‐sample a 2D mask by integer factor ds.\"\"\"\n",
    "    return mask[::ds, ::ds]\n",
    "\n",
    "def estimate_affine_transform(\n",
    "    mask_ref_ds: np.ndarray,\n",
    "    mask_mov_ds: np.ndarray,\n",
    "    criteria: tuple,\n",
    "    warp_init: np.ndarray = None\n",
    ") -> (np.ndarray, float):\n",
    "    \"\"\"\n",
    "    Estimate a 2×3 affine warp that maps mask_mov_ds → mask_ref_ds\n",
    "    via ECC. Returns (warp_matrix, correlation_coefficient).\n",
    "    \"\"\"\n",
    "    if warp_init is None:\n",
    "        warp_init = np.eye(2, 3, dtype=np.float32)\n",
    "    cc, warp_matrix = cv2.findTransformECC(\n",
    "        templateImage = mask_ref_ds.astype(np.float32),\n",
    "        inputImage    = mask_mov_ds.astype(np.float32),\n",
    "        warpMatrix    = warp_init,\n",
    "        motionType    = cv2.MOTION_AFFINE,\n",
    "        criteria      = criteria,\n",
    "        inputMask     = None,\n",
    "        gaussFiltSize = 1\n",
    "    )\n",
    "    return warp_matrix\n",
    "\n",
    "def compute_border_color(img: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Compute the mode of each channel in an RGB image and\n",
    "    return it as a BGR tuple for use in cv2.borderValue.\n",
    "    \"\"\"\n",
    "    # faster than np.unique for 8‐bit data\n",
    "    modes = []\n",
    "    for c in range(3):\n",
    "        channel = img[..., c].ravel()\n",
    "        # bincount of 0–255\n",
    "        counts = np.bincount(channel, minlength=256)\n",
    "        modes.append(int(np.argmax(counts)))\n",
    "    # modes = [mode_R, mode_G, mode_B]\n",
    "    return (modes[2], modes[1], modes[0])\n",
    "\n",
    "def upsample_warp_matrix(warp_ds: np.ndarray, ds: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a 2×3 matrix estimated on downsampled masks,\n",
    "    scale the translation terms back up to full‐res.\n",
    "    \"\"\"\n",
    "    M_full = warp_ds.copy()\n",
    "    M_full[0, 2] *= ds\n",
    "    M_full[1, 2] *= ds\n",
    "    return M_full\n",
    "\n",
    "def warp_image_with_affine(\n",
    "    img: np.ndarray,\n",
    "    M: np.ndarray,\n",
    "    output_shape: tuple,\n",
    "    border_color: tuple,\n",
    "    interp=cv2.INTER_NEAREST\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply a 2×3 affine M to img, producing output_shape=(w,h),\n",
    "    filling outside pixels with border_color.\n",
    "    \"\"\"\n",
    "    flags = interp | cv2.WARP_INVERSE_MAP\n",
    "    return cv2.warpAffine(\n",
    "        src         = img,\n",
    "        M           = M,\n",
    "        dsize       = output_shape,\n",
    "        flags       = flags,\n",
    "        borderMode  = cv2.BORDER_CONSTANT,\n",
    "        borderValue = border_color\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f6952a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 8\n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-7)\n",
    "\n",
    "# Gather your input TIFFs\n",
    "im_pth = 'test_data/cropped_sections'\n",
    "images = sorted([\n",
    "    os.path.join(im_pth, f)\n",
    "    for f in os.listdir(im_pth)\n",
    "    if f.lower().endswith('.tif')\n",
    "])\n",
    "\n",
    "# Prepare output folder\n",
    "out_dir = 'test_data/cropped_sections/aligned'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 1) Save the first image unchanged, and build its mask\n",
    "ref_path = images[0]\n",
    "current_ref = imread(ref_path)\n",
    "imwrite(os.path.join(out_dir, os.path.basename(ref_path)), current_ref)\n",
    "current_ref_mask = get_mask(current_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f2a6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in images[1:]:\n",
    "    mov = imread(img_path)\n",
    "    mov_mask = get_mask(mov)\n",
    "\n",
    "    # downsample masks\n",
    "    r_ds = downsample_mask(current_ref_mask, ds)\n",
    "    m_ds = downsample_mask(mov_mask, ds)\n",
    "\n",
    "    # ECC on downsampled → upsample warp\n",
    "    warp_ds = estimate_affine_transform(r_ds, m_ds, criteria)\n",
    "    M_full  = upsample_warp_matrix(warp_ds, ds)\n",
    "\n",
    "    # compute fill color from moving image\n",
    "    fill = compute_border_color(mov)\n",
    "\n",
    "    # warp and save\n",
    "    h, w = current_ref.shape[:2]\n",
    "    aligned = warp_image_with_affine(mov, M_full, (w, h), fill)\n",
    "    out_p  = os.path.join(out_dir, os.path.basename(img_path))\n",
    "    imwrite(out_p, aligned)\n",
    "\n",
    "    # update reference for next iteration\n",
    "    current_ref = aligned\n",
    "    current_ref_mask = get_mask(current_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_im_path = 'test_data/cropped_sections/aligned'\n",
    "aligned_ims = sorted([os.path.join(aligned_im_path, f) for f in os.listdir(aligned_im_path) if f.endswith('.tif')])\n",
    "\n",
    "# Determine grid size: 4 columns, dynamic rows\n",
    "n = len(aligned_ims)\n",
    "cols = 4\n",
    "rows = round(n / cols)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each image in its own subplot\n",
    "for ax, img_path in zip(axes, aligned_ims):\n",
    "    img = imread(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title('Aligned ' + os.path.basename(img_path), fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Turn off any extra axes if number of images < rows*cols\n",
    "for ax in axes[n:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48ce6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
